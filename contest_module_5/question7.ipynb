{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loiphong/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_epochs = 15\n",
    "\n",
    "train_dataset = FashionMNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SwiGLU, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a, b = x.chunk(2, dim=-1)\n",
    "        return a * self.sigmoid(b)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, hidden_dims*2)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dims*2)\n",
    "        self.layer2 = nn.Linear(hidden_dims, hidden_dims*2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dims*2)\n",
    "        self.layer3 = nn.Linear(hidden_dims, hidden_dims*2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dims*2)\n",
    "        self.output = nn.Linear(hidden_dims, output_dims)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                ## using he initialization\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = SwiGLU()(x)\n",
    "        identity = x # skip connection\n",
    "        x = self.layer2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = SwiGLU()(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = SwiGLU()(x)\n",
    "        x = x + identity\n",
    "        out = self.output(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dims=784, hidden_dims=128, output_dims=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train_Loss: 0.5069, Train_Acc: 0.8222\n",
      "Epoch 2/15, Train_Loss: 0.3406, Train_Acc: 0.8766\n",
      "Epoch 3/15, Train_Loss: 0.2944, Train_Acc: 0.8920\n",
      "Epoch 4/15, Train_Loss: 0.2615, Train_Acc: 0.9051\n",
      "Epoch 5/15, Train_Loss: 0.2384, Train_Acc: 0.9118\n",
      "Epoch 6/15, Train_Loss: 0.2174, Train_Acc: 0.9199\n",
      "Epoch 7/15, Train_Loss: 0.2002, Train_Acc: 0.9267\n",
      "Epoch 8/15, Train_Loss: 0.1837, Train_Acc: 0.9320\n",
      "Epoch 9/15, Train_Loss: 0.1707, Train_Acc: 0.9371\n",
      "Epoch 10/15, Train_Loss: 0.1551, Train_Acc: 0.9433\n",
      "Epoch 11/15, Train_Loss: 0.1465, Train_Acc: 0.9456\n",
      "Epoch 12/15, Train_Loss: 0.1326, Train_Acc: 0.9523\n",
      "Epoch 13/15, Train_Loss: 0.1235, Train_Acc: 0.9543\n",
      "Epoch 14/15, Train_Loss: 0.1113, Train_Acc: 0.9595\n",
      "Epoch 15/15, Train_Loss: 0.1053, Train_Acc: 0.9621\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):    \n",
    "    t_loss = 0\n",
    "    t_acc = 0\n",
    "    cnt = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        t_loss += loss.item()\n",
    "        t_acc += (torch.argmax(outputs, 1) == y).sum().item()\n",
    "        cnt += len(y)\n",
    "\n",
    "    t_loss /= len(train_loader)\n",
    "    t_acc /= cnt\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train_Loss: {t_loss:.4f}, Train_Acc: {t_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
