{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1153f33d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([3.0, 2.0, 1], dtype=torch.float)\n",
    "y = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "wh = torch.tensor([[0.8, -1.0],\n",
    "                   [0.4, -0.6],\n",
    "                   [0.0, 0.0]], dtype=torch.float) \n",
    "\n",
    "wz = torch.tensor([\n",
    "    [0.3, 0.2, 0.1],\n",
    "    [-0.4, -1.0, 0.2],\n",
    "    [0,0,0]\n",
    "    ], dtype=torch.float)\n",
    "# Forward pass\n",
    "# Hidden layer\n",
    "h = torch.matmul(X, wh)\n",
    "h = torch.nn.functional.relu(h)\n",
    "\n",
    "# Output layer\n",
    "h = torch.cat([h, torch.tensor([1.0])])  # \n",
    "z = torch.matmul(h, wz)\n",
    "y_pred = torch.nn.functional.softmax(z, dim=0)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9919)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(z.unsqueeze(0), y_pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cau 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0523, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "class Question6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Question6, self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2, 3)\n",
    "        with torch.no_grad():   \n",
    "            self.linear2.weight.data = torch.tensor([\n",
    "                [0.3, -0.4],\n",
    "                [0.2, -1.0],\n",
    "                [0.1, 0.2],\n",
    "            ])\n",
    "            self.linear2.bias.data = torch.tensor([0.0, 0.0, 0.0], dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "model = Question6()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# calculate loss\n",
    "X = torch.tensor([3.0, 2.0], dtype=torch.float)\n",
    "y = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "y_pred = model(X)\n",
    "loss = loss_fn(y_pred.unsqueeze(0), y)\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
